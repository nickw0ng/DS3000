{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS 3000 HW 4\n",
    "\n",
    "Due: Friday July 19th @ 11:59 PM EST\n",
    "\n",
    "### Submission Instructions\n",
    "Submit this `ipynb` file to Gradescope (this can also be done via the assignment on Canvas).  To ensure that your submitted files represent your latest code, make sure to give a fresh `Kernel > Restart & Run All` just before uploading the files to gradescope.\n",
    "\n",
    "### Tips for success\n",
    "- Start early\n",
    "- Make use of Piazza\n",
    "- Make use of Office hour\n",
    "- Remember to use cells and headings to make the notebook easy to read (if a grader cannot find the answer to a problem, you will receive no points for it)\n",
    "- Under no circumstances may one student view or share their ungraded homework or quiz with another student [(see also)](http://www.northeastern.edu/osccr/academic-integrity), though you are welcome to **talk about** (not show each other) the problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: AZ Quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.1 (15 points)\n",
    "\n",
    "AZ Quotes is one of the websites to provide multiple quotes and sorted by different ways. A quote usually has a text and an author name. \n",
    "\n",
    "<img src=\"https://i.ibb.co/wht5NB0/Screenshot-from-2022-02-23-05-14-26.png\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "Write a function, `clean_quote()` which scrapes all the quotes from https://www.azquotes.com/quotes/topics/positive.html:\n",
    "\n",
    "```python\n",
    "url = 'https://www.azquotes.com/quotes/topics/positive.html'\n",
    "html = get_url(url)\n",
    "df_quote = clean_quote(html)\n",
    "df_quote.head()\n",
    "```\n",
    "\n",
    "gives:\n",
    "\n",
    "|   |          author    |                                              text |\n",
    "|--:|-------------------:|--------------------------------------------------:|\n",
    "| 0 | Mahatma Gandhi     | Keep your thoughts positive because your thoug... |\n",
    "| 1 | Alice Morse Earle  | Every day may not be good... but there's somet... |\n",
    "| 2 | Nicky Gumbel       | You can't change how people treat you or what ... |\n",
    "| 3 | Winston Churchill  | The POSITIVE THINKER sees the INVISIBLE, feels... |\n",
    "| 4 |Paramahansa Yogananda| If you want to be sad, no one in the world can... |\n",
    "\n",
    "After writing the function, run the above code to verify it works.\n",
    "\n",
    "Hint: There are 25 quotes after you scrape the page. However, you may get more items when you scrape the quotes. Feel free to select only the 1:26 to get rid of some other items. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "  \n",
    "def get_url(url):\n",
    "    \"\"\" gets html from url\n",
    "    \n",
    "    Args:\n",
    "        url (str): a url\n",
    "        \n",
    "    Returns:\n",
    "        html (str): the html from the url\n",
    "    \"\"\"\n",
    "    response = requests.get(url)\n",
    "    return response.text\n",
    "    \n",
    "\n",
    "def clean_quote(html):\n",
    "    \"\"\" scrapes quotes from azquote and creates a dataframe with author and text\n",
    "    \n",
    "    Args:\n",
    "        html (str): html text object from brainyquote\n",
    "        \n",
    "    Returns:\n",
    "        clean_df (DataFrame): DataFrame with columns\n",
    "                                author (str): name of the author\n",
    "                                text (str): text of the quote\n",
    "    \"\"\"\n",
    "    \n",
    "    # This parses the HTML content and find all div elements with the class 'wrap-block'\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    quotes = soup.find_all('div', class_='wrap-block')\n",
    "    \n",
    "    # Initializes a list to be used to store the authors and quotes in the link html code\n",
    "    authors = []\n",
    "    texts = []\n",
    "\n",
    "    # This loop iterated through the 25 quotes and finds the text and authors of each of them\n",
    "    for quote in quotes[:25]:\n",
    "        text_tag = quote.find('a', class_='title')\n",
    "        author_tag = quote.find('div', class_='author')\n",
    "        \n",
    "        # This checks to make sure there is an author and quote and then it extracts the information \n",
    "        if text_tag and author_tag:\n",
    "            text = text_tag.text.strip()\n",
    "            author = author_tag.text.strip()\n",
    "            texts.append(text)\n",
    "            authors.append(author)\n",
    "\n",
    "    # Last part creates a dataframe for the authors and quotes and returns it \n",
    "    clean_df = pd.DataFrame({'author': authors, 'text': texts})\n",
    "    return clean_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mahatma Gandhi</td>\n",
       "      <td>Keep your thoughts positive because your thoug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alice Morse Earle</td>\n",
       "      <td>Every day may not be good... but there's somet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Winston Churchill</td>\n",
       "      <td>The POSITIVE THINKER sees the INVISIBLE, feels...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nicky Gumbel</td>\n",
       "      <td>You can't change how people treat you or what ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Horace</td>\n",
       "      <td>Carpe diem! Rejoice while you are alive; enjoy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                               text\n",
       "0     Mahatma Gandhi  Keep your thoughts positive because your thoug...\n",
       "1  Alice Morse Earle  Every day may not be good... but there's somet...\n",
       "2  Winston Churchill  The POSITIVE THINKER sees the INVISIBLE, feels...\n",
       "3       Nicky Gumbel  You can't change how people treat you or what ...\n",
       "4             Horace  Carpe diem! Rejoice while you are alive; enjoy..."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.azquotes.com/quotes/topics/positive.html'\n",
    "html = get_url(url)\n",
    "df_quote = clean_quote(html)\n",
    "df_quote.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.2 (20 points)\n",
    "\n",
    "Navigate to each quote's own webpage and you'll find more information about the tags for each quotes: https://www.azquotes.com/quote/361010?ref=positive\n",
    "\n",
    "Store the tags associated with each quote too.  For example, the quote above has tags: `Hope`, `Positive`, `Inspirational`, `Happiness` and a lot of others.  Think carefully about how you store the tags so that one may easily understand how many times each tag (e.g. `Positive`) appears in your dataframe with simple pandas manipulations.\n",
    "\n",
    "You can update the functions in part 1.1. Run your function in the end and show the head of the data frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that there may be multiple classes, tags, id, etc. that  could lead to the correct data frame\n",
    "\n",
    "def get_quote_tags(html):\n",
    "    \"\"\" grabs the tags from each of the quotes from the html of azquote\n",
    "    \n",
    "    Args:\n",
    "        html (str): html text object from brainyquote\n",
    "        \n",
    "    Returns:\n",
    "        clean_df (DataFrame): DataFrame with columns\n",
    "                                author (str): name of the author\n",
    "                                text (str): text of the quote\n",
    "                                tags (str): string with tags from quote\n",
    "    \n",
    "    \"\"\"\n",
    "    _ = BeautifulSoup(html, 'html.parser')\n",
    "    quotes = _.find_all('div', class_='wrap-block')[:25]\n",
    "    \n",
    "    authors = []\n",
    "    texts = []\n",
    "    tags_list = []\n",
    "    \n",
    "    for quote in quotes:\n",
    "        author_tag = quote.find('div', class_='author')\n",
    "        text_tag = quote.find('a', class_='title')\n",
    "        \n",
    "        author = author_tag.text.strip()\n",
    "        text = text_tag.text.strip()\n",
    "        quote_url = 'https://www.azquotes.com' + text_tag.get('href')\n",
    "            \n",
    "\n",
    "        quote_html = get_url(quote_url)\n",
    "        quote_soup = BeautifulSoup(quote_html, 'html.parser')\n",
    "        tags = [tag.text for tag in quote_soup.find_all('a', class_='tag')]\n",
    "        tags_str = ', '.join(tags)\n",
    "            \n",
    "        authors.append(author)\n",
    "        texts.append(text)\n",
    "        tags_list.append(tags_str)\n",
    "    \n",
    "    \n",
    "    clean_df = pd.DataFrame({\n",
    "        'author': authors,\n",
    "        'text': texts,\n",
    "        'tags': tags_list\n",
    "    })\n",
    "    return clean_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              author                                               text tags\n",
      "0     Mahatma Gandhi  Keep your thoughts positive because your thoug...     \n",
      "1  Alice Morse Earle  Every day may not be good... but there's somet...     \n",
      "2  Winston Churchill  The POSITIVE THINKER sees the INVISIBLE, feels...     \n",
      "3       Nicky Gumbel  You can't change how people treat you or what ...     \n",
      "4             Horace  Carpe diem! Rejoice while you are alive; enjoy...     \n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.azquotes.com/quotes/topics/positive.html'\n",
    "html = get_url(url)\n",
    "if html:\n",
    "    df_quote = get_quote_tags(html)\n",
    "    print(df_quote.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fantasy Football"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.1 (10 points)\n",
    "\n",
    "In Fantasy Football, real NFL players gain points for fans at home based on some scoring criteria (which differs based on the website, but in all cases more points is better). Use the following link https://fantasydata.com/nfl/fantasy-football-leaders?scope=season&scoring=fpts_ppr&order_by=fpts_ppr&sort_dir=desc&sp=2023_REG and `pd.read_html` to extract 2023 fantasy football regular season data. Notice that this data has double layers of column names. You can re-name the columns for the easier plotting later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Unnamed: 0_level_0   Unnamed: 1_level_0 Unnamed: 2_level_0  \\\n",
      "                  RK                 NAME               TEAM   \n",
      "0                  1          CeeDee Lamb                DAL   \n",
      "1                  2           Josh Allen                BUF   \n",
      "2                  3  Christian McCaffrey                 SF   \n",
      "3                  4          Tyreek Hill                MIA   \n",
      "4                  5          Jalen Hurts                PHI   \n",
      "\n",
      "  Unnamed: 3_level_0 Unnamed: 4_level_0 PASSING         RUSHING     RECEIVING  \\\n",
      "                 POS                 GP     YDS  TD INT     YDS  TD       REC   \n",
      "0                 WR                 17       0   0   0     113   2       135   \n",
      "1                 QB                 17    4306  29  18     524  15         0   \n",
      "2                 RB                 16       0   0   0    1459  14        67   \n",
      "3                 WR                 16       0   0   0      15   0       119   \n",
      "4                 QB                 17    3858  23  15     605  15         0   \n",
      "\n",
      "            DEFENSE           Unnamed: 17_level_0 Unnamed: 18_level_0  \n",
      "    YDS  TD     SCK INT FF FR              FPTS/G                FPTS  \n",
      "0  1749  12       0   0  0  0                23.7               403.2  \n",
      "1     0   0       0   0  0  0                23.1               392.6  \n",
      "2   564   7       0   0  0  0                24.5               391.3  \n",
      "3  1799  13       0   0  0  0                23.5               376.4  \n",
      "4     0   0       0   0  0  0                21.0               356.8  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "url = 'https://fantasydata.com/nfl/fantasy-football-leaders?scope=season&scoring=fpts_ppr&order_by=fpts_ppr&sort_dir=desc&sp=2023_REG'\n",
    "\n",
    "dfs = pd.read_html(url)\n",
    "\n",
    "df = dfs[0]\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.2 (10 points)\n",
    "\n",
    "Filter the data for QB and then make a graph which plots `PASSING_YDS` on the x-axis against `FPTS` on the y-axis, and colors the points based on `PASSING_TD`. Use `plotly` and include the `Name` and `Team` as `hover_data`. Make sure the graph is well labeled, titled, and includes a legend. Then, in a Markdown cell, discuss in **at least 3** sentences your interpretation of the graph.\n",
    "\n",
    "- **Note**: if you are not an american football fan, in brief the Quarterback's role is to throw the ball to other players in the hopes of scoring a touchdown (if you want a much more technical description, you may also read a bit [here](https://en.wikipedia.org/wiki/Quarterback))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install plotly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.3 (10 points)\n",
    "\n",
    "It seems that right now the data size is small thus hard to achieve any conclusion. There are multiple ways we can extend the data. One of the easier way is to get data from different season. Complete the following functions `multiple_year_df()` such that it takes a starting year and an end year then return all the data for each regular season within the range (inclusive both start and end). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_year_df(start, end):\n",
    "    \"\"\" gives the leaderboard during the regular season from start year and end year\n",
    "    \n",
    "    Args:\n",
    "        start (int): the first year has been included in the data\n",
    "        end (int): the last year has been included in the data\n",
    "        \n",
    "    Returns:\n",
    "        fantasy_full (DataFrame): a large data frame for all the regular season data from year `start` to year `end`. \n",
    "    \n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.4 (15 points)\n",
    "\n",
    "Use the `multiple_year_df()` function to create data frames from year 2014 to 2023. Filter for  the four main offensive positions (QB, WR, RB, TE) and then create, using subplots in a single plot, histograms for each positions' `FPTS`. Make sure the subplots are on the same scale, well labeled, and titled. You can use `plt.ylim(0, 70)` to set the y range. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2.5 (20 points)\n",
    "\n",
    "Another way to extend the data to access each QB's web page and extract their own data across different years. However, by extracting the table directly, we cannot access the herf link directly. Therefore we need to manully crawl the web page. Notice that we only extract the information for each QB instead of other players. In the end, you can re-create the figure in part 2.2. Here is a general approach for you to start with: (no need to write in functions)\n",
    "\n",
    "1. get `soup` for the 2023 regular season leading board data (code provided)\n",
    "2. Look for which class represents the player's corresponding webpage. You need to save two things here: `href_list` to save the information for each QB's webpage and `name_list` to save each QB's name. We can go through every line in the leading board data, if it is a QB, we save the herf and name, otherwise, just skip it. \n",
    "3. For each herf link in the `href_list`, extract the data on the page. Notice that there are mutiple tables in players'own webpage. We need the one with stats and FTPS. You may also want to remove the last row in the table since it is a summary data and add a column for the player's name. Merge (concat) all the data. You can rename the column and index. \n",
    "4. Re-create the plot in part 2.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://fantasydata.com/nfl/fantasy-football-leaders?scope=season&scoring=fpts_ppr&order_by=fpts_ppr&sort_dir=desc&sp=2023_REG'\n",
    "html_text = requests.get(url).text\n",
    "soup = BeautifulSoup(html_text)\n",
    "herf_list = []\n",
    "name_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
