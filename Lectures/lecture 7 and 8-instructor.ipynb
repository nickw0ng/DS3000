{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DS3000 Lecture 7 and 8\n",
    "\n",
    "### Admin:\n",
    "- HW 3 due on Monday\n",
    "- HW 4 posted on Tuesday and due on Friday\n",
    "- Lecture 9 will be a lab. Finish the lab will earn 1 extra credict\n",
    "- Project description will be released this week\n",
    "\n",
    "### Content:\n",
    "- OpenWeather API pipeline\n",
    "- Intro to Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pipeline: What is it?\n",
    "\n",
    "A data pipeline is a collection of functions* which split all the functionality of our data collection and processing\n",
    "\n",
    "(*can be other structures too, but it may be easier to first understand each as a function)\n",
    "\n",
    "\n",
    "# Why build a data pipeline?\n",
    "\n",
    "- Allows pipeline to be run in parts (rather than the whole thing)\n",
    "- Allows pipeline to be built by different programmers working on different parts in parallel\n",
    "- Allows us to test each piece of our code seperately\n",
    "- Allows for modification / re-use of different sections\n",
    "\n",
    "What we call a \"Data Pipeline\" here is a specific instance of \"Factoring\" a piece of software, splitting up its functionality into pieces.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# OpenWeather API Pipeline Activity\n",
    "\n",
    "OpenWeather API offers a few different queries (see [here](https://openweathermap.org/api) for details):\n",
    "- 3-hour Forecast 5 days (which we have access to)\n",
    "- Air Pollution API\n",
    "- etc.\n",
    "\n",
    "\n",
    "**Goal:**\n",
    "\n",
    "Build a library of functions which can be pieced together to support the collection, cleaning and display of features from OpenWeather into a scatter plot of two features.\n",
    "\n",
    "### Lets design one together: \n",
    "\n",
    "(think: input/outputs -> handwritten notes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Plan out a pipeline\n",
    "\n",
    "Write a few 'empty' functions including little more than the docstring:\n",
    "\n",
    "```python\n",
    "def some_fnc(a_string, a_list):\n",
    "    \"\"\" processes a string and a list (somehow)\n",
    "    \n",
    "    Args:\n",
    "        a_string (str): an input string which ...\n",
    "        a_list (list): a list which describes ...\n",
    "        \n",
    "    Returns:\n",
    "        output (dict): the output dict which is ...\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "and a script which uses them:\n",
    "\n",
    "```python\n",
    "# inputs (not necessarily complete)\n",
    "lat = -42\n",
    "lon = 73\n",
    "\n",
    "some_output = some_fnc(lat, lon)\n",
    "some_other_output = some_other_fnc(some_output)\n",
    "\n",
    "```\n",
    "\n",
    "which would, if the functions worked, produce a graph like this (note: this starts Oct 6, because I made it yesterday):\n",
    "\n",
    "<img src=\"https://i.ibb.co/Ct0JtRJ/newplot-1.png\" width=500\\img>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What might these empty functions look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "\n",
    "def openweather_onecall(latlon_tuple, api_key, units='imperial'):\n",
    "    \"\"\" returns weather data from one location via onecall\n",
    "    \n",
    "    https://openweathermap.org/api/one-call-api \n",
    "    \n",
    "    Args:\n",
    "        latlon_tuple (tuple): first element is lattitude,\n",
    "            second is longitude\n",
    "        api_key (str): API key required to access data\n",
    "        units (str): 'imperial', 'standard', 'metric'\n",
    "        \n",
    "    Returns:\n",
    "        weather_dict (dict): a nested dictionary (tree) which\n",
    "            contains weather data\n",
    "    \"\"\"\n",
    "    # build url\n",
    "    lat, lon = latlon_tuple\n",
    "    url = f'https://api.openweathermap.org/data/2.5/forecast?lat={lat}&lon={lon}&APPID={api_key}&units={units}'\n",
    "\n",
    "    # get url as a string\n",
    "    url_text = requests.get(url).text\n",
    "    \n",
    "    # convert json to a nested dict\n",
    "    weather_dict = json.loads(url_text)\n",
    "    \n",
    "    return weather_dict\n",
    "\n",
    "def get_clean_df_daily(weather_dict):\n",
    "    \"\"\" formats daily_dict to a pandas data frame\n",
    "    \n",
    "    see https://openweathermap.org/api/one-call-api for\n",
    "    full daily_dict specification\n",
    "    \n",
    "    Args:\n",
    "        weather_dict (list): list of dictionaries of 3-hour window\n",
    "            weather features\n",
    "            \n",
    "    Returns:\n",
    "        df_daily (pd.DataFrame): each row is weather from 3-hour window\n",
    "    \"\"\"\n",
    "    hour_dict = weather_dict['list'][0]['main']\n",
    "    hour_dict['datetime'] = weather_dict['list'][0]['dt_txt']\n",
    "\n",
    "    df_hourly = pd.Series(hour_dict)\n",
    "\n",
    "    df_hourly = pd.DataFrame(df_hourly).transpose()\n",
    "    \n",
    "    index = 0\n",
    "    for hour_index in weather_dict['list']:\n",
    "\n",
    "        hour_dict = hour_index['main']\n",
    "        hour_dict['datetime'] = hour_index['dt_txt']\n",
    "\n",
    "        s_hour = pd.Series(hour_dict)\n",
    "    \n",
    "        #df_hourly = df_hourly.append(s_hour, ignore_index=True)\n",
    "        df_hourly.loc[str(index),:] = s_hour\n",
    "    \n",
    "        index = index + 1\n",
    "\n",
    "    df_hourly = df_hourly.iloc[1:,]   \n",
    "    \n",
    "    return df_hourly\n",
    "\n",
    "def scatter_plotly(df, feat_x, feat_y, f_html='scatter.html'):\n",
    "    \"\"\" creates a plotly scatter plot, exports as html \n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): pandas dataframe\n",
    "        x_feat (str): x axis of scatter\n",
    "        y_feat (str): y axis of scatter\n",
    "        f_html (str): output html file\n",
    "        \n",
    "    Returns:\n",
    "        f_html (str): output html file\n",
    "    \"\"\"\n",
    "    # creat scatter plot\n",
    "    fig = px.scatter(df, x=feat_x, y=feat_y)\n",
    "\n",
    "    # export scatter to html\n",
    "    plotly.offline.plot(fig, filename=f_html)\n",
    "    \n",
    "    return f_html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "feat_x = 'datetime'\n",
    "feat_y = 'temp_max'\n",
    "latlon_tuple = -42, 70\n",
    "units = 'imperial'\n",
    "api_key = '2afdede234eabfa52612efba55bcc8ac'\n",
    "\n",
    "# get data\n",
    "weather_dict = openweather_onecall(latlon_tuple, \n",
    "                                   units=units,\n",
    "                                   api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>feels_like</th>\n",
       "      <th>temp_min</th>\n",
       "      <th>temp_max</th>\n",
       "      <th>pressure</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>grnd_level</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temp_kf</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46.78</td>\n",
       "      <td>39.09</td>\n",
       "      <td>46.44</td>\n",
       "      <td>46.78</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>69</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2024-07-15 18:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46.76</td>\n",
       "      <td>38.97</td>\n",
       "      <td>46.67</td>\n",
       "      <td>46.76</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>70</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2024-07-15 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.45</td>\n",
       "      <td>41.79</td>\n",
       "      <td>48.45</td>\n",
       "      <td>48.45</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-16 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.78</td>\n",
       "      <td>42.35</td>\n",
       "      <td>48.78</td>\n",
       "      <td>48.78</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>1032</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-16 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.97</td>\n",
       "      <td>43.11</td>\n",
       "      <td>48.97</td>\n",
       "      <td>48.97</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>1033</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-16 06:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    temp feels_like temp_min temp_max pressure sea_level grnd_level humidity  \\\n",
       "0  46.78      39.09    46.44    46.78     1032      1032       1032       69   \n",
       "1  46.76      38.97    46.67    46.76     1032      1032       1032       70   \n",
       "2  48.45      41.79    48.45    48.45     1032      1032       1032       64   \n",
       "3  48.78      42.35    48.78    48.78     1032      1032       1032       72   \n",
       "4  48.97      43.11    48.97    48.97     1033      1033       1033       70   \n",
       "\n",
       "  temp_kf             datetime  \n",
       "0    0.19  2024-07-15 18:00:00  \n",
       "1    0.05  2024-07-15 21:00:00  \n",
       "2       0  2024-07-16 00:00:00  \n",
       "3       0  2024-07-16 03:00:00  \n",
       "4       0  2024-07-16 06:00:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean weather dict (make dataframe from dict, process timestamps etc)\n",
    "df_daily = get_clean_df_daily(weather_dict)\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make scatter\n",
    "f_html = scatter_plotly(df_daily, feat_x=feat_x, feat_y=feat_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping\n",
    "* Using programs or scripts to pretend to browse websites, examine the content on those websites, retrieve and extract data from those websites\n",
    "* Why scrape?\n",
    "    * if an API is available for a service, we will nearly always prefer the API to scraping\n",
    "    * ... but not all services have APIs or the available APIs are too expensive for our project\n",
    "    * newly published information might not yet be available through ready datasets\n",
    "* Downsides of scraping:\n",
    "    * no reference documentation (unlike APIs)\n",
    "    * no guarantee that a webpage we scrape will look and work the same way the next day (might need to rewrite the whole scraper)\n",
    "    * if it violates the terms of service it might be seen as a felony (https://www.aclu.org/cases/sandvig-v-barr-challenge-cfaa-prohibition-uncovering-racial-discrimination-online)\n",
    "    * legal and moral greyzone (even if the ToS does not disallow it, somebody has to pay for the traffic and when you're scraping you're not looking at ads)\n",
    "    * ... but everbody does it anyway (https://www.hollywoodreporter.com/thr-esq/genius-says-it-caught-google-lyricfind-redhanded-stealing-lyrics-400m-suit-1259383)\n",
    "* Web scraping pipeline:\n",
    "    * because the webpages might change their structure it's extra important to keep the crawling/extraction step separate from transformations and loading\n",
    "    * ETL (Extraction-Transform-Load):\n",
    "        * **Crawl**: open a given URL using requests and get the HTML source;\n",
    "        * **Extract**: extract interesting content from the webpage's source.\n",
    "        * **Transform**: our usual unit conversions, etc\n",
    "        * **Load**: representing the data in an easy way for storage and analysis\n",
    "    * **Pro tip**: it's usually a good idea to not only store the transformed data, but also the raw HTML source - because the webpages might change and we might be late to realize we're not extracting right. If we have the original HTML source we can go back to it\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, whether is it OK to be scrapped?\n",
    "\n",
    "robots.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best case scenario\n",
    "Some webpages publish their data in the form of simple tables. In these (rare) cases we can just use pandas .read_html to scrape this data:\n",
    "\n",
    "https://www.espn.com/nba/team/stats/_/name/bos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                    Name\n",
       " 0        Jayson Tatum SF\n",
       " 1        Jaylen Brown SG\n",
       " 2       Derrick White PG\n",
       " 3        Jrue Holiday PG\n",
       " 4   Kristaps Porzingis C\n",
       " 5           Al Horford C\n",
       " 6    Payton Pritchard PG\n",
       " 7          Sam Hauser SF\n",
       " 8          Luke Kornet C\n",
       " 9      Oshae Brissett SF\n",
       " 10    Xavier Tillman F *\n",
       " 11       Neemias Queta C\n",
       " 12     Svi Mykhailiuk SG\n",
       " 13    Jaden Springer G *\n",
       " 14        Jordan Walsh G\n",
       " 15                 Total,\n",
       "     GP    GS   MIN    PTS   OR    DR   REB   AST  STL  BLK    TO    PF  AST/TO\n",
       " 0   19  19.0  40.4   25.0  0.9   8.8   9.7   6.3  1.1  0.7   2.6   2.8     2.4\n",
       " 1   19  19.0  37.2   23.9  1.2   4.8   5.9   3.3  1.2  0.6   2.7   2.7     1.2\n",
       " 2   19  19.0  35.6   16.7  1.0   3.3   4.3   4.1  0.9  1.2   0.8   2.3     4.8\n",
       " 3   19  19.0  37.9   13.2  1.9   4.2   6.1   4.4  1.1  0.6   1.5   2.1     2.9\n",
       " 4    7   4.0  23.6   12.3  0.6   3.9   4.4   1.1  0.7  1.6   0.7   2.1     1.6\n",
       " 5   19  15.0  30.3    9.2  1.8   5.2   7.0   2.1  0.8  0.8   0.6   1.5     3.3\n",
       " 6   19   0.0  18.7    6.4  0.7   1.2   1.9   2.1  0.2  0.0   0.7   1.2     2.9\n",
       " 7   19   0.0  14.9    5.4  0.4   1.7   2.2   0.6  0.3  0.2   0.2   1.1     3.7\n",
       " 8   13   0.0  10.2    3.0  1.5   1.7   3.2   0.5  0.1  0.4   0.5   0.8     1.2\n",
       " 9   10   0.0   5.5    1.6  0.3   1.1   1.4   0.0  0.3  0.2   0.1   0.2     0.0\n",
       " 10   8   0.0   8.6    1.5  0.5   1.3   1.8   0.4  0.4  0.4   0.4   0.9     1.0\n",
       " 11   3   0.0   4.3    1.3  0.3   0.7   1.0   0.0  0.0  0.3   0.0   0.0     0.0\n",
       " 12   8   0.0   4.0    1.0  0.1   0.5   0.6   0.1  0.1  0.0   0.3   0.4     0.5\n",
       " 13   4   0.0   5.5    1.0  0.0   0.8   0.8   0.3  0.0  0.3   0.5   0.3     0.5\n",
       " 14   3   0.0   3.7    0.7  0.0   0.7   0.7   0.0  0.0  0.0   0.0   0.0     0.0\n",
       " 15  19   NaN   NaN  108.8  9.7  33.4  43.1  23.8  6.3  5.4  10.2  15.7     2.3,\n",
       "                     Name\n",
       " 0        Jayson Tatum SF\n",
       " 1        Jaylen Brown SG\n",
       " 2       Derrick White PG\n",
       " 3        Jrue Holiday PG\n",
       " 4   Kristaps Porzingis C\n",
       " 5           Al Horford C\n",
       " 6    Payton Pritchard PG\n",
       " 7          Sam Hauser SF\n",
       " 8          Luke Kornet C\n",
       " 9      Oshae Brissett SF\n",
       " 10    Xavier Tillman F *\n",
       " 11       Neemias Queta C\n",
       " 12     Svi Mykhailiuk SG\n",
       " 13    Jaden Springer G *\n",
       " 14        Jordan Walsh G\n",
       " 15                 Total,\n",
       "      FGM   FGA   FG%   3PM   3PA    3P%   FTM   FTA    FT%   2PM   2PA   2P%  \\\n",
       " 0    8.4  19.6  42.7   2.1   7.3   28.3   6.2   7.2   86.1   6.3  12.3  51.3   \n",
       " 1    9.2  17.8  51.6   1.9   5.8   32.7   3.6   5.4   66.0   7.3  12.1  60.7   \n",
       " 2    5.7  12.7  45.2   3.4   8.5   40.4   1.8   2.0   92.1   2.3   4.2  55.0   \n",
       " 3    5.1  10.2  50.3   1.8   4.6   40.2   1.1   1.2   95.5   3.3   5.6  58.5   \n",
       " 4    4.0   8.6  46.7   1.4   4.1   34.5   2.9   3.1   90.9   2.6   4.4  58.1   \n",
       " 5    3.5   7.3  47.8   1.8   5.0   36.8   0.4   0.6   63.6   1.6   2.3  72.1   \n",
       " 6    2.3   5.5  41.9   1.2   3.2   38.3   0.6   0.6   91.7   1.1   2.4  46.7   \n",
       " 7    1.9   4.4  42.9   1.4   3.7   38.0   0.2   0.2  100.0   0.5   0.7  69.2   \n",
       " 8    1.1   1.6  66.7   0.0   0.0    0.0   0.8   1.0   84.6   1.1   1.6  66.7   \n",
       " 9    0.6   1.1  54.5   0.2   0.2  100.0   0.2   0.4   50.0   0.4   0.9  44.4   \n",
       " 10   0.6   1.0  62.5   0.1   0.1  100.0   0.1   0.1  100.0   0.5   0.9  57.1   \n",
       " 11   0.7   1.0  66.7   0.0   0.0    0.0   0.0   0.0    0.0   0.7   1.0  66.7   \n",
       " 12   0.4   1.5  25.0   0.3   1.1   22.2   0.0   0.0    0.0   0.1   0.4  33.3   \n",
       " 13   0.5   0.8  66.7   0.0   0.0    0.0   0.0   0.0    0.0   0.5   0.8  66.7   \n",
       " 14   0.3   1.0  33.3   0.0   0.3    0.0   0.0   0.0    0.0   0.3   0.7  50.0   \n",
       " 15  39.3  83.8  46.9  14.5  40.2   36.0  15.7  19.3   81.2  24.8  43.6  56.9   \n",
       " \n",
       "     SC-EFF  SH-EFF  \n",
       " 0    1.277    0.48  \n",
       " 1    1.339    0.57  \n",
       " 2    1.320    0.59  \n",
       " 3    1.295    0.59  \n",
       " 4    1.433    0.55  \n",
       " 5    1.261    0.61  \n",
       " 6    1.162    0.53  \n",
       " 7    1.226    0.59  \n",
       " 8    1.857    0.67  \n",
       " 9    1.455    0.64  \n",
       " 10   1.500    0.69  \n",
       " 11   1.333    0.67  \n",
       " 12   0.667    0.33  \n",
       " 13   1.333    0.67  \n",
       " 14   0.667    0.33  \n",
       " 15   1.298    0.56  ]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.read_html('https://www.espn.com/nba/team/stats/_/name/bos')\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jayson Tatum SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Brown SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Derrick White PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jrue Holiday PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristaps Porzingis C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al Horford C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payton Pritchard PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sam Hauser SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Luke Kornet C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oshae Brissett SF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Xavier Tillman F *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neemias Queta C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Svi Mykhailiuk SG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jaden Springer G *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jordan Walsh G</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Total</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name\n",
       "0        Jayson Tatum SF\n",
       "1        Jaylen Brown SG\n",
       "2       Derrick White PG\n",
       "3        Jrue Holiday PG\n",
       "4   Kristaps Porzingis C\n",
       "5           Al Horford C\n",
       "6    Payton Pritchard PG\n",
       "7          Sam Hauser SF\n",
       "8          Luke Kornet C\n",
       "9      Oshae Brissett SF\n",
       "10    Xavier Tillman F *\n",
       "11       Neemias Queta C\n",
       "12     Svi Mykhailiuk SG\n",
       "13    Jaden Springer G *\n",
       "14        Jordan Walsh G\n",
       "15                 Total"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(table)\n",
    "table[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>GP</th>\n",
       "      <th>GS</th>\n",
       "      <th>MIN</th>\n",
       "      <th>PTS</th>\n",
       "      <th>OR</th>\n",
       "      <th>DR</th>\n",
       "      <th>REB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>...</th>\n",
       "      <th>3PA</th>\n",
       "      <th>3P%</th>\n",
       "      <th>FTM</th>\n",
       "      <th>FTA</th>\n",
       "      <th>FT%</th>\n",
       "      <th>2PM</th>\n",
       "      <th>2PA</th>\n",
       "      <th>2P%</th>\n",
       "      <th>SC-EFF</th>\n",
       "      <th>SH-EFF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jayson Tatum SF</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>40.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.3</td>\n",
       "      <td>28.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>86.1</td>\n",
       "      <td>6.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>1.277</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jaylen Brown SG</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.2</td>\n",
       "      <td>23.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>...</td>\n",
       "      <td>5.8</td>\n",
       "      <td>32.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>66.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.1</td>\n",
       "      <td>60.7</td>\n",
       "      <td>1.339</td>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Derrick White PG</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>...</td>\n",
       "      <td>8.5</td>\n",
       "      <td>40.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.0</td>\n",
       "      <td>92.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.320</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jrue Holiday PG</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>37.9</td>\n",
       "      <td>13.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4.6</td>\n",
       "      <td>40.2</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>95.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>58.5</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristaps Porzingis C</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>34.5</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>90.9</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>58.1</td>\n",
       "      <td>1.433</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Al Horford C</td>\n",
       "      <td>19</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.3</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>63.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.3</td>\n",
       "      <td>72.1</td>\n",
       "      <td>1.261</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payton Pritchard PG</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>6.4</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.2</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>91.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>46.7</td>\n",
       "      <td>1.162</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sam Hauser SF</td>\n",
       "      <td>19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>3.7</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>69.2</td>\n",
       "      <td>1.226</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Luke Kornet C</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84.6</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1.857</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oshae Brissett SF</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>1.455</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Xavier Tillman F *</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>57.1</td>\n",
       "      <td>1.500</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Neemias Queta C</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Svi Mykhailiuk SG</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1</td>\n",
       "      <td>22.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>33.3</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jaden Springer G *</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.8</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1.333</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jordan Walsh G</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Total</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>33.4</td>\n",
       "      <td>43.1</td>\n",
       "      <td>23.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>...</td>\n",
       "      <td>40.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>19.3</td>\n",
       "      <td>81.2</td>\n",
       "      <td>24.8</td>\n",
       "      <td>43.6</td>\n",
       "      <td>56.9</td>\n",
       "      <td>1.298</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Name  GP    GS   MIN    PTS   OR    DR   REB   AST  STL  \\\n",
       "0        Jayson Tatum SF  19  19.0  40.4   25.0  0.9   8.8   9.7   6.3  1.1   \n",
       "1        Jaylen Brown SG  19  19.0  37.2   23.9  1.2   4.8   5.9   3.3  1.2   \n",
       "2       Derrick White PG  19  19.0  35.6   16.7  1.0   3.3   4.3   4.1  0.9   \n",
       "3        Jrue Holiday PG  19  19.0  37.9   13.2  1.9   4.2   6.1   4.4  1.1   \n",
       "4   Kristaps Porzingis C   7   4.0  23.6   12.3  0.6   3.9   4.4   1.1  0.7   \n",
       "5           Al Horford C  19  15.0  30.3    9.2  1.8   5.2   7.0   2.1  0.8   \n",
       "6    Payton Pritchard PG  19   0.0  18.7    6.4  0.7   1.2   1.9   2.1  0.2   \n",
       "7          Sam Hauser SF  19   0.0  14.9    5.4  0.4   1.7   2.2   0.6  0.3   \n",
       "8          Luke Kornet C  13   0.0  10.2    3.0  1.5   1.7   3.2   0.5  0.1   \n",
       "9      Oshae Brissett SF  10   0.0   5.5    1.6  0.3   1.1   1.4   0.0  0.3   \n",
       "10    Xavier Tillman F *   8   0.0   8.6    1.5  0.5   1.3   1.8   0.4  0.4   \n",
       "11       Neemias Queta C   3   0.0   4.3    1.3  0.3   0.7   1.0   0.0  0.0   \n",
       "12     Svi Mykhailiuk SG   8   0.0   4.0    1.0  0.1   0.5   0.6   0.1  0.1   \n",
       "13    Jaden Springer G *   4   0.0   5.5    1.0  0.0   0.8   0.8   0.3  0.0   \n",
       "14        Jordan Walsh G   3   0.0   3.7    0.7  0.0   0.7   0.7   0.0  0.0   \n",
       "15                 Total  19   NaN   NaN  108.8  9.7  33.4  43.1  23.8  6.3   \n",
       "\n",
       "    ...   3PA    3P%   FTM   FTA    FT%   2PM   2PA   2P%  SC-EFF  SH-EFF  \n",
       "0   ...   7.3   28.3   6.2   7.2   86.1   6.3  12.3  51.3   1.277    0.48  \n",
       "1   ...   5.8   32.7   3.6   5.4   66.0   7.3  12.1  60.7   1.339    0.57  \n",
       "2   ...   8.5   40.4   1.8   2.0   92.1   2.3   4.2  55.0   1.320    0.59  \n",
       "3   ...   4.6   40.2   1.1   1.2   95.5   3.3   5.6  58.5   1.295    0.59  \n",
       "4   ...   4.1   34.5   2.9   3.1   90.9   2.6   4.4  58.1   1.433    0.55  \n",
       "5   ...   5.0   36.8   0.4   0.6   63.6   1.6   2.3  72.1   1.261    0.61  \n",
       "6   ...   3.2   38.3   0.6   0.6   91.7   1.1   2.4  46.7   1.162    0.53  \n",
       "7   ...   3.7   38.0   0.2   0.2  100.0   0.5   0.7  69.2   1.226    0.59  \n",
       "8   ...   0.0    0.0   0.8   1.0   84.6   1.1   1.6  66.7   1.857    0.67  \n",
       "9   ...   0.2  100.0   0.2   0.4   50.0   0.4   0.9  44.4   1.455    0.64  \n",
       "10  ...   0.1  100.0   0.1   0.1  100.0   0.5   0.9  57.1   1.500    0.69  \n",
       "11  ...   0.0    0.0   0.0   0.0    0.0   0.7   1.0  66.7   1.333    0.67  \n",
       "12  ...   1.1   22.2   0.0   0.0    0.0   0.1   0.4  33.3   0.667    0.33  \n",
       "13  ...   0.0    0.0   0.0   0.0    0.0   0.5   0.8  66.7   1.333    0.67  \n",
       "14  ...   0.3    0.0   0.0   0.0    0.0   0.3   0.7  50.0   0.667    0.33  \n",
       "15  ...  40.2   36.0  15.7  19.3   81.2  24.8  43.6  56.9   1.298    0.56  \n",
       "\n",
       "[16 rows x 28 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_stats = pd.concat(table[:2], axis = 1)\n",
    "player_stats = pd.concat([player_stats, table[3]], axis = 1)\n",
    "player_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# baseball instead of basketball?\n",
    "# https://www.baseball-reference.com/teams/BOS/2022.shtml\n",
    "\n",
    "base_table = pd.read_html('https://www.baseball-reference.com/teams/BOS/2022.shtml')\n",
    "len(base_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rk</th>\n",
       "      <th>Pos</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>W</th>\n",
       "      <th>L</th>\n",
       "      <th>W-L%</th>\n",
       "      <th>ERA</th>\n",
       "      <th>G</th>\n",
       "      <th>GS</th>\n",
       "      <th>...</th>\n",
       "      <th>WP</th>\n",
       "      <th>BF</th>\n",
       "      <th>ERA+</th>\n",
       "      <th>FIP</th>\n",
       "      <th>WHIP</th>\n",
       "      <th>H9</th>\n",
       "      <th>HR9</th>\n",
       "      <th>BB9</th>\n",
       "      <th>SO9</th>\n",
       "      <th>SO/W</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>SP</td>\n",
       "      <td>Nick Pivetta</td>\n",
       "      <td>29</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>.455</td>\n",
       "      <td>4.56</td>\n",
       "      <td>33</td>\n",
       "      <td>33</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>773</td>\n",
       "      <td>92</td>\n",
       "      <td>4.42</td>\n",
       "      <td>1.380</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>SP</td>\n",
       "      <td>Michael Wacha</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>.846</td>\n",
       "      <td>3.32</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>515</td>\n",
       "      <td>127</td>\n",
       "      <td>4.14</td>\n",
       "      <td>1.115</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>SP</td>\n",
       "      <td>Rich Hill*</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>.533</td>\n",
       "      <td>4.27</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>526</td>\n",
       "      <td>98</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1.303</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>2.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>SP</td>\n",
       "      <td>Nathan Eovaldi</td>\n",
       "      <td>32</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>.667</td>\n",
       "      <td>3.87</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "      <td>109</td>\n",
       "      <td>4.30</td>\n",
       "      <td>1.235</td>\n",
       "      <td>9.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>SP</td>\n",
       "      <td>Kutter Crawford</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>.333</td>\n",
       "      <td>5.47</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>334</td>\n",
       "      <td>77</td>\n",
       "      <td>4.34</td>\n",
       "      <td>1.422</td>\n",
       "      <td>9.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SP</td>\n",
       "      <td>Josh Winckowski</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>.417</td>\n",
       "      <td>5.89</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>316</td>\n",
       "      <td>72</td>\n",
       "      <td>4.95</td>\n",
       "      <td>1.592</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Rk</td>\n",
       "      <td>Pos</td>\n",
       "      <td>Name</td>\n",
       "      <td>Age</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>W-L%</td>\n",
       "      <td>ERA</td>\n",
       "      <td>G</td>\n",
       "      <td>GS</td>\n",
       "      <td>...</td>\n",
       "      <td>WP</td>\n",
       "      <td>BF</td>\n",
       "      <td>ERA+</td>\n",
       "      <td>FIP</td>\n",
       "      <td>WHIP</td>\n",
       "      <td>H9</td>\n",
       "      <td>HR9</td>\n",
       "      <td>BB9</td>\n",
       "      <td>SO9</td>\n",
       "      <td>SO/W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>CL</td>\n",
       "      <td>John Schreiber</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>.500</td>\n",
       "      <td>2.22</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>257</td>\n",
       "      <td>190</td>\n",
       "      <td>2.50</td>\n",
       "      <td>0.985</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>10.2</td>\n",
       "      <td>3.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RP</td>\n",
       "      <td>Ryan Brasier</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>.000</td>\n",
       "      <td>5.78</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>263</td>\n",
       "      <td>73</td>\n",
       "      <td>3.61</td>\n",
       "      <td>1.299</td>\n",
       "      <td>9.8</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>RP</td>\n",
       "      <td>Austin Davis*</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>.667</td>\n",
       "      <td>5.47</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>254</td>\n",
       "      <td>77</td>\n",
       "      <td>3.94</td>\n",
       "      <td>1.564</td>\n",
       "      <td>9.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>RP</td>\n",
       "      <td>Hirokazu Sawamura</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>.500</td>\n",
       "      <td>3.73</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>221</td>\n",
       "      <td>113</td>\n",
       "      <td>4.16</td>\n",
       "      <td>1.421</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>1.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>RP</td>\n",
       "      <td>Matt Strahm*</td>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>.500</td>\n",
       "      <td>3.83</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>193</td>\n",
       "      <td>110</td>\n",
       "      <td>3.72</td>\n",
       "      <td>1.231</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rk</td>\n",
       "      <td>Pos</td>\n",
       "      <td>Name</td>\n",
       "      <td>Age</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>W-L%</td>\n",
       "      <td>ERA</td>\n",
       "      <td>G</td>\n",
       "      <td>GS</td>\n",
       "      <td>...</td>\n",
       "      <td>WP</td>\n",
       "      <td>BF</td>\n",
       "      <td>ERA+</td>\n",
       "      <td>FIP</td>\n",
       "      <td>WHIP</td>\n",
       "      <td>H9</td>\n",
       "      <td>HR9</td>\n",
       "      <td>BB9</td>\n",
       "      <td>SO9</td>\n",
       "      <td>SO/W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Garrett Whitlock</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>.667</td>\n",
       "      <td>3.45</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>311</td>\n",
       "      <td>122</td>\n",
       "      <td>3.29</td>\n",
       "      <td>1.021</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tanner Houck</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>.556</td>\n",
       "      <td>3.15</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>247</td>\n",
       "      <td>134</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.183</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>2.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brayan Bello</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>.200</td>\n",
       "      <td>4.71</td>\n",
       "      <td>13</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>268</td>\n",
       "      <td>90</td>\n",
       "      <td>2.94</td>\n",
       "      <td>1.779</td>\n",
       "      <td>11.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>8.6</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tyler Danish</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>.750</td>\n",
       "      <td>5.13</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>173</td>\n",
       "      <td>82</td>\n",
       "      <td>4.97</td>\n",
       "      <td>1.289</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>2.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Matt Barnes</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>.000</td>\n",
       "      <td>4.31</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>176</td>\n",
       "      <td>98</td>\n",
       "      <td>3.87</td>\n",
       "      <td>1.437</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jake Diekman*</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>.833</td>\n",
       "      <td>4.23</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>171</td>\n",
       "      <td>100</td>\n",
       "      <td>4.96</td>\n",
       "      <td>1.487</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kaleb Ort</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>.333</td>\n",
       "      <td>6.35</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>134</td>\n",
       "      <td>67</td>\n",
       "      <td>4.84</td>\n",
       "      <td>1.765</td>\n",
       "      <td>11.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>1.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hansel Robles</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>.250</td>\n",
       "      <td>5.84</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>73</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.581</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>7.7</td>\n",
       "      <td>1.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Connor Seabold</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>.000</td>\n",
       "      <td>11.29</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>98</td>\n",
       "      <td>38</td>\n",
       "      <td>6.38</td>\n",
       "      <td>2.345</td>\n",
       "      <td>17.2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>9.3</td>\n",
       "      <td>2.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eduard Bazardo</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>2.76</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>65</td>\n",
       "      <td>156</td>\n",
       "      <td>6.05</td>\n",
       "      <td>0.980</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Phillips Valdéz</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>.000</td>\n",
       "      <td>4.41</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>97</td>\n",
       "      <td>3.91</td>\n",
       "      <td>1.163</td>\n",
       "      <td>6.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Zack Kelly</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>3.95</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>59</td>\n",
       "      <td>109</td>\n",
       "      <td>4.28</td>\n",
       "      <td>1.317</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jeurys Familia</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>.333</td>\n",
       "      <td>6.10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>71</td>\n",
       "      <td>5.14</td>\n",
       "      <td>1.645</td>\n",
       "      <td>8.7</td>\n",
       "      <td>0.9</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Darwinzon Hernández*</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>.000</td>\n",
       "      <td>21.60</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>20</td>\n",
       "      <td>12.71</td>\n",
       "      <td>3.300</td>\n",
       "      <td>18.9</td>\n",
       "      <td>5.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.2</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chris Sale*</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>.000</td>\n",
       "      <td>3.18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>141</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.059</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Franklin German</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.00</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>25</td>\n",
       "      <td>10.61</td>\n",
       "      <td>2.750</td>\n",
       "      <td>15.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Michael Feliz</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>172</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0.900</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>10.8</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yolmer Sanchez</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>64</td>\n",
       "      <td>3.11</td>\n",
       "      <td>3.000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jackie Bradley Jr.</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>64</td>\n",
       "      <td>10.11</td>\n",
       "      <td>4.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reese McGuire</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kevin Plawecki</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.11</td>\n",
       "      <td>1.000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yu Chang</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Team Totals</td>\n",
       "      <td>30.1</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>.481</td>\n",
       "      <td>4.53</td>\n",
       "      <td>162</td>\n",
       "      <td>162</td>\n",
       "      <td>...</td>\n",
       "      <td>60</td>\n",
       "      <td>6167</td>\n",
       "      <td>93</td>\n",
       "      <td>4.17</td>\n",
       "      <td>1.354</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.5</td>\n",
       "      <td>2.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rank in 15 AL teams</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rk</td>\n",
       "      <td>Pos</td>\n",
       "      <td>Name</td>\n",
       "      <td>Age</td>\n",
       "      <td>W</td>\n",
       "      <td>L</td>\n",
       "      <td>W-L%</td>\n",
       "      <td>ERA</td>\n",
       "      <td>G</td>\n",
       "      <td>GS</td>\n",
       "      <td>...</td>\n",
       "      <td>WP</td>\n",
       "      <td>BF</td>\n",
       "      <td>ERA+</td>\n",
       "      <td>FIP</td>\n",
       "      <td>WHIP</td>\n",
       "      <td>H9</td>\n",
       "      <td>HR9</td>\n",
       "      <td>BB9</td>\n",
       "      <td>SO9</td>\n",
       "      <td>SO/W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rk  Pos                  Name   Age   W   L   W-L%    ERA    G   GS  ...  \\\n",
       "0     1   SP          Nick Pivetta    29  10  12   .455   4.56   33   33  ...   \n",
       "1     2   SP         Michael Wacha    30  11   2   .846   3.32   23   23  ...   \n",
       "2     3   SP            Rich Hill*    42   8   7   .533   4.27   26   26  ...   \n",
       "3     4   SP        Nathan Eovaldi    32   6   3   .667   3.87   20   20  ...   \n",
       "4     5   SP       Kutter Crawford    26   3   6   .333   5.47   21   12  ...   \n",
       "5     6   SP       Josh Winckowski    24   5   7   .417   5.89   15   14  ...   \n",
       "6    Rk  Pos                  Name   Age   W   L   W-L%    ERA    G   GS  ...   \n",
       "7     7   CL        John Schreiber    28   4   4   .500   2.22   64    0  ...   \n",
       "8     8   RP          Ryan Brasier    34   0   3   .000   5.78   68    0  ...   \n",
       "9     9   RP         Austin Davis*    29   2   1   .667   5.47   50    3  ...   \n",
       "10   10   RP     Hirokazu Sawamura    34   1   1   .500   3.73   49    0  ...   \n",
       "11   11   RP          Matt Strahm*    30   4   4   .500   3.83   50    0  ...   \n",
       "12   Rk  Pos                  Name   Age   W   L   W-L%    ERA    G   GS  ...   \n",
       "13   12  NaN      Garrett Whitlock    26   4   2   .667   3.45   31    9  ...   \n",
       "14   13  NaN          Tanner Houck    26   5   4   .556   3.15   32    4  ...   \n",
       "15   14  NaN          Brayan Bello    23   2   8   .200   4.71   13   11  ...   \n",
       "16   15  NaN          Tyler Danish    27   3   1   .750   5.13   32    0  ...   \n",
       "17   16  NaN           Matt Barnes    32   0   4   .000   4.31   44    0  ...   \n",
       "18   17  NaN         Jake Diekman*    35   5   1   .833   4.23   44    0  ...   \n",
       "19   18  NaN             Kaleb Ort    30   1   2   .333   6.35   25    0  ...   \n",
       "20   19  NaN         Hansel Robles    31   1   3   .250   5.84   26    0  ...   \n",
       "21   20  NaN        Connor Seabold    26   0   4   .000  11.29    5    5  ...   \n",
       "22   21  NaN        Eduard Bazardo    26   1   0  1.000   2.76   12    0  ...   \n",
       "23   22  NaN       Phillips Valdéz    30   0   1   .000   4.41   13    0  ...   \n",
       "24   23  NaN            Zack Kelly    27   1   0  1.000   3.95   13    0  ...   \n",
       "25   24  NaN        Jeurys Familia    32   1   2   .333   6.10   10    0  ...   \n",
       "26   25  NaN  Darwinzon Hernández*    25   0   1   .000  21.60    7    0  ...   \n",
       "27   26  NaN           Chris Sale*    33   0   1   .000   3.18    2    2  ...   \n",
       "28   27  NaN       Franklin German    24   0   0    NaN  18.00    5    0  ...   \n",
       "29   28  NaN         Michael Feliz    29   0   0    NaN   2.70    1    0  ...   \n",
       "30   29  NaN        Yolmer Sanchez    30   0   0    NaN   9.00    1    0  ...   \n",
       "31   30  NaN    Jackie Bradley Jr.    32   0   0    NaN   9.00    1    0  ...   \n",
       "32   31  NaN         Reese McGuire    27   0   0    NaN   0.00    1    0  ...   \n",
       "33   32  NaN        Kevin Plawecki    31   0   0    NaN   0.00    1    0  ...   \n",
       "34   33  NaN              Yu Chang    26   0   0    NaN    NaN    0    0  ...   \n",
       "35  NaN  NaN           Team Totals  30.1  78  84   .481   4.53  162  162  ...   \n",
       "36  NaN  NaN   Rank in 15 AL teams   NaN   9   6    NaN     14  NaN  NaN  ...   \n",
       "37   Rk  Pos                  Name   Age   W   L   W-L%    ERA    G   GS  ...   \n",
       "\n",
       "     WP    BF  ERA+    FIP   WHIP    H9  HR9   BB9   SO9  SO/W  \n",
       "0    10   773    92   4.42  1.380   8.8  1.4   3.7   8.8  2.40  \n",
       "1     4   515   127   4.14  1.115   7.8  1.3   2.2   7.4  3.35  \n",
       "2     0   526    98   3.92  1.303   9.0  1.1   2.7   7.9  2.95  \n",
       "3     2   460   109   4.30  1.235   9.5  1.7   1.6   8.5  5.15  \n",
       "4     4   334    77   4.34  1.422   9.4  1.4   3.4   9.0  2.66  \n",
       "5     0   316    72   4.95  1.592  10.9  1.3   3.5   5.6  1.63  \n",
       "6    WP    BF  ERA+    FIP   WHIP    H9  HR9   BB9   SO9  SO/W  \n",
       "7     4   257   190   2.50  0.985   6.2  0.4   2.6  10.2  3.89  \n",
       "8     1   263    73   3.61  1.299   9.8  1.3   1.9   9.2  4.92  \n",
       "9     1   254    77   3.94  1.564   9.3  0.8   4.8  10.1  2.10  \n",
       "10    8   221   113   4.16  1.421   8.0  0.7   4.8   7.1  1.48  \n",
       "11    2   193   110   3.72  1.231   7.7  1.0   3.4  10.5  3.06  \n",
       "12   WP    BF  ERA+    FIP   WHIP    H9  HR9   BB9   SO9  SO/W  \n",
       "13    2   311   122   3.29  1.021   7.5  1.1   1.7   9.4  5.47  \n",
       "14    3   247   134   3.30  1.183   7.4  0.5   3.3   8.4  2.55  \n",
       "15    2   268    90   2.94  1.779  11.8  0.2   4.2   8.6  2.04  \n",
       "16    1   173    82   4.97  1.289   8.9  1.6   2.7   7.1  2.67  \n",
       "17    4   176    98   3.87  1.437   8.2  0.5   4.8   7.7  1.62  \n",
       "18    5   171   100   4.96  1.487   6.3  1.2   7.0  12.0  1.70  \n",
       "19    1   134    67   4.84  1.765  11.1  1.3   4.8   8.6  1.80  \n",
       "20    0   111    73   5.75  1.581   9.1  1.8   5.1   7.7  1.50  \n",
       "21    4    98    38   6.38  2.345  17.2  2.5   3.9   9.3  2.38  \n",
       "22    1    65   156   6.05  0.980   6.6  2.2   2.2   6.1  2.75  \n",
       "23    1    72    97   3.91  1.163   6.6  0.0   3.9   7.2  1.86  \n",
       "24    0    59   109   4.28  1.317   9.2  1.3   2.6   7.2  2.75  \n",
       "25    0    46    71   5.14  1.645   8.7  0.9   6.1   7.0  1.14  \n",
       "26    0    43    20  12.71  3.300  18.9  5.4  10.8  12.2  1.13  \n",
       "27    0    25   141   2.41  1.059   7.9  0.0   1.6   7.9  5.00  \n",
       "28    0    23    25  10.61  2.750  15.8  4.5   9.0   9.0  1.00  \n",
       "29    0    13   172   6.41  0.900   2.7  2.7   5.4  10.8  2.00  \n",
       "30    0     6    64   3.11  3.000  27.0  0.0   0.0   0.0   NaN  \n",
       "31    0     7    64  10.11  4.000   9.0  0.0  27.0   9.0  0.33  \n",
       "32    0     3   NaN   3.11  0.000   0.0  0.0   0.0   0.0   NaN  \n",
       "33    0     4   NaN   3.11  1.000   9.0  0.0   0.0   0.0   NaN  \n",
       "34    0     0   NaN    NaN    NaN   NaN  NaN   NaN   NaN   NaN  \n",
       "35   60  6167    93   4.17  1.354   8.9  1.2   3.3   8.5  2.56  \n",
       "36  NaN   NaN   NaN    NaN    NaN   NaN  NaN   NaN   NaN   NaN  \n",
       "37   WP    BF  ERA+    FIP   WHIP    H9  HR9   BB9   SO9  SO/W  \n",
       "\n",
       "[38 rows x 34 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_table[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Messy Data\n",
    "\n",
    "Notice that the baseball data are quite a bit messier than the basketball data. In web scraping, you are beholden to the format of the website (.html) and will almost certainly have to clean data (sometimes extensively) after scraping it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic HTML\n",
    "Web pages are written in HTML. The source of https://sapiezynski.com/ds3000/scraping/01.html looks like this:\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <head>\n",
    "        <!-- comments in HTML are marked like this -->\n",
    "        \n",
    "        <!-- the head tag contains the meta information not displayed but helps browsers render the page -->\n",
    "    </head>\n",
    "    <body>\n",
    "         <!-- This is the body of the document that contains all the visible elements.-->\n",
    "        <h1>Heading 1</h1>\n",
    "        <h2>This is what heading 2 looks like</h2>\n",
    "        \n",
    "        <p>Text is usually in paragraphs.\n",
    "            New lines and multiple consecutive whitespace characters are ignored.</p>\n",
    "\n",
    "<p>Unlike in python indentation is only a good practice but it doesn't change functionality. In fact, all of this HTML could be (and often is in real webpages) just writen as a single line.</p>   \n",
    "        \n",
    "        <p>Links are created using the \"a\" tag: \n",
    "            <a href=\"https://www.google.com\">Click here to google.</a>\n",
    "            href is an attirbute of the a tag that specify where the link points to.</p>\n",
    "        \n",
    "        \n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "The keywords in `<>` brackets are called tags. They open with `<tag>` and close with `</tag>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      "    <head>\n",
      "        <!-- comments in HTML are marked like this -->\n",
      "        \n",
      "        <!-- the head tag contains the meta information not displayed but helps browsers render the page -->\n",
      "    </head>\n",
      "    <body>\n",
      "         <!-- This is the body of the document that contains all the visible elements.-->\n",
      "        <h1>Heading 1</h1>\n",
      "        <h2>This is what heading 2 looks like</h2>\n",
      "        \n",
      "        <p>Text is usually in paragraphs.\n",
      "            New lines and multiple consecutive whitespace characters are ignored.</p>\n",
      "\n",
      "<p>Unlike in python indentation is only a good practice but it doesn't change functionality. In fact, all of this HTML could be (and often is in real webpages) just writen as a single line.</p>   \n",
      "        \n",
      "        <p>Links are created using the \"a\" tag: \n",
      "            <a href=\"https://www.google.com\">Click here to google.</a>\n",
      "            href is an attirbute of the a tag that specify where the link points to.</p>\n",
      "        \n",
      "        \n",
      "    </body>\n",
      "</html>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Getting the html content in Python\n",
    "import requests\n",
    "\n",
    "response = requests.get('https://sapiezynski.com/ds3000/scraping/01.html')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html><head><title>nytimes.com</title><style>#cmsg{animation: A 1.5s;}@keyframes A{0%{opacity:0;}99%{opacity:0;}100%{opacity:1;}}</style></head><body style=\"margin:0\"><p id=\"cmsg\">Please enable JS and disable any ad blocker</p><script data-cfasync=\"false\">var dd={'rt':'c','cid':'AHrlqAAAAAMA8wYL_R-WW1IAmyGCHw==','hsh':'499AE34129FA4E4FABC31582C3075D','t':'bv','s':17439,'e':'ec0e6e6eeeda672a40dff8fd801bf6a4d75b96fe9135653c4abb4e50d53e3ec5','host':'geo.captcha-delivery.com'}</script><script data-cfasync=\"false\" src=\"https://ct.captcha-delivery.com/c.js\"></script></body></html>\n"
     ]
    }
   ],
   "source": [
    "# sometimes this doesn't quite work the way you want (c'est la vie with web scraping)\n",
    "response2 = requests.get('https://www.nytimes.com/2019/03/10/style/what-is-tik-tok.html')\n",
    "print(response2.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beautiful Soup\n",
    "\n",
    "Even if the .html does look relatively clean, it's still just a big string. How can we deal with it? Luckily there is a module made for just this purpose, and it's even a magic command which we can install directly in jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Using cached bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\yangx\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\yangx\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=c09542241be07caaa3a7ba8e73bbed263656c48a06e7a2d08745e378c42e81b5\n",
      "  Stored in directory: c:\\users\\yangx\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\yangx\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "#pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://sapiezynski.com/ds3000/scraping/01.html\"\n",
    "str_html = requests.get(url).text\n",
    "soup = BeautifulSoup(str_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<head>\n",
       "<!-- comments in HTML are marked like this -->\n",
       "<!-- the head tag contains the meta information not displayed but helps browsers render the page -->\n",
       "</head>\n",
       "<body>\n",
       "<!-- This is the body of the document that contains all the visible elements.-->\n",
       "<h1>Heading 1</h1>\n",
       "<h2>This is what heading 2 looks like</h2>\n",
       "<p>Text is usually in paragraphs.\n",
       "            New lines and multiple consecutive whitespace characters are ignored.</p>\n",
       "<p>Unlike in python indentation is only a good practice but it doesn't change functionality. In fact, all of this HTML could be (and often is in real webpages) just writen as a single line.</p>\n",
       "<p>Links are created using the \"a\" tag: \n",
       "            <a href=\"https://www.google.com\">Click here to google.</a>\n",
       "            href is an attirbute of the a tag that specify where the link points to.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>Text is usually in paragraphs.\n",
       "             New lines and multiple consecutive whitespace characters are ignored.</p>,\n",
       " <p>Unlike in python indentation is only a good practice but it doesn't change functionality. In fact, all of this HTML could be (and often is in real webpages) just writen as a single line.</p>,\n",
       " <p>Links are created using the \"a\" tag: \n",
       "             <a href=\"https://www.google.com\">Click here to google.</a>\n",
       "             href is an attirbute of the a tag that specify where the link points to.</p>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>Text is usually in paragraphs.\n",
       "            New lines and multiple consecutive whitespace characters are ignored.</p>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(soup.find_all('p')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Text is usually in paragraphs.\\n            New lines and multiple consecutive whitespace characters are ignored.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('p')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text is usually in paragraphs.\n",
      "            New lines and multiple consecutive whitespace characters are ignored.\n",
      "-------------------\n",
      "Unlike in python indentation is only a good practice but it doesn't change functionality. In fact, all of this HTML could be (and often is in real webpages) just writen as a single line.\n",
      "-------------------\n",
      "Links are created using the \"a\" tag: \n",
      "            Click here to google.\n",
      "            href is an attirbute of the a tag that specify where the link points to.\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "for paragraph in soup.find_all('p'):\n",
    "    print(paragraph.text)\n",
    "    print('-------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `.find_all()` on subtrees of soup object\n",
    "\n",
    "\n",
    "The `.find_all()` method works not only on the whole `soup` object, but also on subtrees of the soup object.  \n",
    "\n",
    "Consider the site at https://sapiezynski.com/ds3000/scraping/02.html:\n",
    "\n",
    "```html\n",
    "<html>\n",
    "    <body>\n",
    "        <p>The links in this paragraph point to search engines, like <a href=\"https://duckduckgo.com\">DuckDuckGo</a>, <a href=\"https://google.com\">Google</a>, <a href=\"https://bing.com\">Bing</a></p>\n",
    "        \n",
    "        <p>The links in this paragraph point to Internet browsers, like <a href=\"https://firefox.com\">Firefox</a>, <a href=\"https://chrome.com\">Chrome</a>, <a href=\"https://opera.com\">Opera</a></p>.\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "**Goal**: Grab links from the first paragraph only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<html>\n",
       "<body>\n",
       "<p>The links in this paragraph point to search engines, like <a href=\"https://duckduckgo.com\">DuckDuckGo</a>, <a href=\"https://google.com\">Google</a>, <a href=\"https://bing.com\">Bing</a></p>\n",
       "<p>The links in this paragraph point to Internet browsers, like <a href=\"https://firefox.com\">Firefox</a>, <a href=\"https://chrome.com\">Chrome</a>, <a href=\"https://opera.com\">Opera</a>.</p>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://sapiezynski.com/ds3000/scraping/02.html\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text)\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p>The links in this paragraph point to search engines, like <a href=\"https://duckduckgo.com\">DuckDuckGo</a>, <a href=\"https://google.com\">Google</a>, <a href=\"https://bing.com\">Bing</a></p>,\n",
       " <p>The links in this paragraph point to Internet browsers, like <a href=\"https://firefox.com\">Firefox</a>, <a href=\"https://chrome.com\">Chrome</a>, <a href=\"https://opera.com\">Opera</a>.</p>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_all = soup.find_all('p')\n",
    "p_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some syntactic sugar: \n",
    "To get the first tag under a soup object, refer to it as an attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<p>The links in this paragraph point to search engines, like <a href=\"https://duckduckgo.com\">DuckDuckGo</a>, <a href=\"https://google.com\">Google</a>, <a href=\"https://bing.com\">Bing</a></p>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"https://duckduckgo.com\">DuckDuckGo</a>,\n",
       " <a href=\"https://google.com\">Google</a>,\n",
       " <a href=\"https://bing.com\">Bing</a>]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a href=\"https://duckduckgo.com\">DuckDuckGo</a>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.p.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://duckduckgo.com\">DuckDuckGo</a>\n",
      "<a href=\"https://firefox.com\">Firefox</a>\n"
     ]
    }
   ],
   "source": [
    "for par in soup.find_all('p'):\n",
    "    print(par.a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying if tags exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "header = soup.h3\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test if a tag exists in a soup object by looking for the first instance of this tag and comparing it to `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tag h3 does not exist\n"
     ]
    }
   ],
   "source": [
    "if soup.h3 is None:\n",
    "    print('the tag h3 does not exist')\n",
    "else:\n",
    "    print('the tag h3 does exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the tag p does exist\n"
     ]
    }
   ],
   "source": [
    "if soup.p is None:\n",
    "    print('the tag p does not exist')\n",
    "else:\n",
    "    print('the tag p does exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags by `class_`\n",
    "\n",
    "**Tip**: This is often one of the most useful ways to localize a particular part of a web page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get soup\n",
    "url = 'https://www.allrecipes.com/search?q=cheese+fondue'\n",
    "responses = requests.get(url)\n",
    "soup = BeautifulSoup(responses.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our **goal** is to get a list of recipes.  Maybe we should find all the `div` tags? What about `span` tags?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "303"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('div'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup.find_all('span'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tags can have multiple \"classes\" they belong to.  For example, in https://www.allrecipes.com/search?q=cheese+fondue the first recipe is encapsulated in this html tag:\n",
    "\n",
    "    <span class=\"card__title\"><span class=\"card__title-text\">Cheese Fondue</span></span>\n",
    "    \n",
    "So this particular span tag belongs to classes:\n",
    "- `card__title`\n",
    "- `card__title-text`\n",
    "    \n",
    "I suspect only our target recipes belong to the `card__title-text` class.  Lets find them all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_list = soup.find_all(class_ = 'card__title-text')\n",
    "len(recipe_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"card__title-text\">Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Best Formula Three-Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Beer Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Classic Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Chef John's Classic Cheese Fondue Is the Ultimate Cheese Lover's Recipe</span>,\n",
       " <span class=\"card__title-text\">Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Quick Fontina Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Basic Fondue</span>,\n",
       " <span class=\"card__title-text\">YouTube + Chill: For Serious Cheese-Lovers Only</span>,\n",
       " <span class=\"card__title-text\">Classic Swiss Fondue</span>,\n",
       " <span class=\"card__title-text\">Crab Cheese Fondue</span>,\n",
       " <span class=\"card__title-text\">Cheese</span>,\n",
       " <span class=\"card__title-text\">25 Best Appetizers to Make if You're Obsessed With Cheese</span>,\n",
       " <span class=\"card__title-text\">How to Make Cheese Sauce From Scratch</span>,\n",
       " <span class=\"card__title-text\">What Is Gruyère Cheese and What Does It Taste Like?</span>,\n",
       " <span class=\"card__title-text\">The Most Popular Recipes of the 1970s</span>,\n",
       " <span class=\"card__title-text\">Tarek's Irish Stout Fondue</span>,\n",
       " <span class=\"card__title-text\">Parmesan Fondue</span>,\n",
       " <span class=\"card__title-text\">Shrimp Fondue</span>,\n",
       " <span class=\"card__title-text\">How To Use Up Those Dried Cheese Scraps From Your Fridge</span>,\n",
       " <span class=\"card__title-text\">Cheddar-Beer Fondue</span>,\n",
       " <span class=\"card__title-text\">Easy Pizza Fondue</span>,\n",
       " <span class=\"card__title-text\">16 Retro Diner Dinner Recipes</span>,\n",
       " <span class=\"card__title-text\">Why Do Some Cheeses Melt Better Than Others?</span>]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why Do Some Cheeses Melt Better Than Others?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_list[23].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding tags by `id`\n",
    "\n",
    "Nearly the same as finding by class, but you'll look for `id=` in the html and pass it to the `id` keyword of `soup.find_all()`.\n",
    "\n",
    "**Goal**: Get the footer from: https://www.scrapethissite.com/\n",
    "\n",
    "\n",
    "\n",
    "```html\n",
    "<section id=\"footer\">\n",
    "        <div class=\"container\">\n",
    "            <div class=\"row\">\n",
    "                <div class=\"col-md-12 text-center text-muted\">\n",
    "                    Lessons and Videos © Hartley Brody 2018\n",
    "                </div><!--.col-->\n",
    "            </div><!--.row-->\n",
    "        </div><!--.container-->\n",
    "    </section>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get soup from url\n",
    "url = 'https://www.scrapethissite.com/'\n",
    "html = requests.get(url)\n",
    "soup = BeautifulSoup(html.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<section id=\"footer\">\n",
       " <div class=\"container\">\n",
       " <div class=\"row\">\n",
       " <div class=\"col-md-12 text-center text-muted\">\n",
       "                     Lessons and Videos © Hartley Brody 2023\n",
       "                 </div><!--.col-->\n",
       " </div><!--.row-->\n",
       " </div><!--.container-->\n",
       " </section>]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(id = 'footer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that you can combine all searches shown above:\n",
    "- tag\n",
    "    - p (paragraph)\n",
    "    - a (link)\n",
    "    - div, span, ...\n",
    "- tag class\n",
    "- tag id\n",
    "\n",
    "```python\n",
    "# finds all links (tag type = 'a'), with given class and id\n",
    "soup.find_all('a', class_='fancy-link', id='blue')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice: \n",
    "\n",
    "**Goal:** Get a list of recipe names from www.allrecipes.com like we did for:\n",
    "\n",
    "https://www.allrecipes.com/search?q=cheese+fondue\n",
    "\n",
    "1. Write function `crawl_recipes(query)` which:\n",
    "    * takes the search phrase (the ingredient) as input argument\n",
    "    * builds the correct url that leads directly to the page that lists the recipes\n",
    "    * uses `requests` to get the content of this page returns the html text of the page\n",
    "1. Write `extract_recipes(text)` which:\n",
    "    * takes the text returned by `crawl_recipes` as argument\n",
    "    * builds a BeautifulSoup object out of that text \n",
    "    * finds names of all recipes\n",
    "        - to identify which tags / classes to `find_all()`, open the page in your browser and \"inspect\" \n",
    "        - start from the recipe object above, and call another `find_all()` to zoom into the recipe name itself\n",
    "    * returns the list of recipe names\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A new function that will help if you wish to query multiple words:\n",
    "\n",
    "`string.replace()`\n",
    "\n",
    "So, if you wish to turn `cheese fondue` into `cheese+fondue`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheese+fondue'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = 'cheese fondue'\n",
    "string = string.replace(\" \", \"+\")\n",
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_recipes(query):\n",
    "    \"\"\" gets html of from allrecipes.com to search query\n",
    "    \n",
    "    Args:\n",
    "        query (str): search string\n",
    "        \n",
    "    Returns:\n",
    "        html_str (str): html response from allreceipes.com\n",
    "    \"\"\"\n",
    "    query = query.replace(\" \", \"+\")\n",
    "    url = f'https://www.allrecipes.com/search?q={query}'\n",
    "    html = requests.get(url).text\n",
    "\n",
    "    return html\n",
    "    \n",
    "def extract_recipes(text):\n",
    "    \"\"\" builds list of recipe names from allrecipies html\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html response from allrecipes.com, see crawl_recipes()\n",
    "        \n",
    "    Returns:\n",
    "        recipe_list (list): list of recipes\n",
    "    \"\"\"\n",
    "    soup = BeautifulSoup(text)\n",
    "    recipe_list = []\n",
    "\n",
    "    for recipe in soup.find_all(class_ = 'card__title-text'):\n",
    "        recipe = recipe.text\n",
    "        recipe_list.append(recipe)\n",
    "\n",
    "    return recipe_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "meatloaf_html = crawl_recipes('meatloaf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recipt_list = extract_recipes(meatloaf_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classic Meatloaf',\n",
       " 'Melt-In-Your-Mouth Meatloaf',\n",
       " 'Best Meatloaf',\n",
       " 'Easy Meatloaf',\n",
       " 'Creamy Mushroom Meatloaf',\n",
       " \"Meatloaf that Doesn't Crumble\",\n",
       " 'Meatloaf Cupcakes',\n",
       " 'Italian Style Turkey Meatloaf',\n",
       " 'Brown Sugar Meatloaf with Ketchup Glaze',\n",
       " \"Chris's Incredible Italian Turkey Meatloaf\",\n",
       " 'Turkey and Quinoa Meatloaf',\n",
       " 'Dill Pickle Meatloaf',\n",
       " \"Kim's Ultimate Meatloaf\",\n",
       " \"Ellen's Buffalo Meatloaf\",\n",
       " 'Sweet and Sour Meatloaf',\n",
       " 'Mushroom Meatloaf',\n",
       " \"Chef John's Meatball-Inspired Meatloaf\",\n",
       " 'Best Turkey Meatloaf',\n",
       " 'Cottage Meatloaf',\n",
       " 'Tennessee Meatloaf',\n",
       " \"Momma's Healthy Meatloaf\",\n",
       " 'Best Ever Meatloaf with Brown Gravy',\n",
       " 'Smoky Chipotle Meatloaf',\n",
       " 'Cheeseburger Meatloaf']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_recipt_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting info from each recipe's own page:\n",
    "\n",
    "When we interact with the webpage in the browser, clicking on the header with the recipe name leads us to the actual recipe. Let's have a look at how it's done. Here is the link (`<a >` tag) for the first and third cards of the meatloaf search:\n",
    "\n",
    "```html\n",
    "<a class=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\" \n",
    "   data-cta=\"\" \n",
    "   data-doc-id=\"6663943\" \n",
    "   data-ordinal=\"1\" \n",
    "   data-tax-levels=\"\" \n",
    "   href=\"https://www.allrecipes.com/recipe/219171/classic-meatloaf/\" \n",
    "   id=\"mntl-card-list-items_1-0\">\n",
    "```\n",
    "\n",
    "```html\n",
    "<a class=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\" \n",
    "   data-cta=\"\" \n",
    "   data-doc-id=\"6663443\" \n",
    "   data-ordinal=\"3\" \n",
    "   data-tax-levels=\"\" \n",
    "   href=\"https://www.allrecipes.com/recipe/223381/melt-in-your-mouth-meat-loaf/\" \n",
    "   id=\"mntl-card-list-items_1-0-2\">\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "meatloaf_html = crawl_recipes('meatloaf')\n",
    "soup = BeautifulSoup(meatloaf_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"comp mntl-card-list-items mntl-document-card mntl-card card card--no-image\" data-doc-id=\"6663943\" data-ordinal=\"1\" data-tax-levels=\"\" href=\"https://www.allrecipes.com/recipe/219171/classic-meatloaf/\" id=\"mntl-card-list-items_1-0\">\n",
       "<div class=\"loc card__top\"><div class=\"card__media mntl-universal-image card__media universal-image__container\"><div class=\"img-placeholder\" style=\"padding-bottom:66.6%;\">\n",
       "<img alt=\"close up view of a sliced meatloaf on a white platter\" class=\"lazyload card__img universal-image__image\" data-expand=\"300\" data-src=\"https://www.allrecipes.com/thmb/EfIedrgpookiaFCI_MCUAmQOUTY=/282x188/filters:no_upscale():max_bytes(150000):strip_icc()/219171-classic-meatloaf-DDMFS-4x3-6b2d4a8c103146c1856eb0bf135bbffe.jpg\" height=\"188\" width=\"282\"/>\n",
       "<noscript>\n",
       "<img alt=\"close up view of a sliced meatloaf on a white platter\" class=\"img--noscript card__img universal-image__image\" height=\"188\" src=\"https://www.allrecipes.com/thmb/EfIedrgpookiaFCI_MCUAmQOUTY=/282x188/filters:no_upscale():max_bytes(150000):strip_icc()/219171-classic-meatloaf-DDMFS-4x3-6b2d4a8c103146c1856eb0bf135bbffe.jpg\" width=\"282\"/>\n",
       "</noscript>\n",
       "</div></div>\n",
       "<div class=\"comp card__favorite mntl-favorite\" id=\"card__favorite_1-0\"> <button aria-label=\"Save Recipe\" class=\"mntl-favorite__link\" data-brand=\"alrcom\" data-check-on-load=\"false\" data-click-tracked=\"false\" data-doc-id=\"6663943\" data-doc-image=\"https://www.allrecipes.com/thmb/htSXhp21PZfJaevG4GTv5PRaLjo=/280x280/filters:no_upscale():max_bytes(150000):strip_icc()/219171-classic-meatloaf-DDMFS-4x3-6b2d4a8c103146c1856eb0bf135bbffe.jpg\" data-doc-title=\"Classic Meatloaf\" data-scroll-to-favorite=\"true\" data-sign-in=\"/authentication/login?regSource=3833&amp;relativeRedirectUrl=\" data-tracking-on=\"card\">\n",
       "<svg class=\"icon save-icon-favorite\">\n",
       "<use href=\"#save-icon-favorite\" xlink:href=\"#save-icon-favorite\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "</button>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"card__content\" data-tag=\"Beef Meatloaf Recipes\">\n",
       "<div class=\"card__header\"></div>\n",
       "<span class=\"card__title\"><span class=\"card__title-text\">Classic Meatloaf</span></span>\n",
       "<div class=\"comp mntl-recipe-card-meta mm-recipes-card-meta\" id=\"mntl-recipe-card-meta_1-0\">\n",
       "<div class=\"comp mntl-recipe-star-rating mm-recipes-star-rating\" id=\"mntl-recipe-star-rating_1-0\">\n",
       "<svg class=\"icon icon-star\">\n",
       "<use href=\"#icon-star\" xlink:href=\"#icon-star\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "<svg class=\"icon icon-star\">\n",
       "<use href=\"#icon-star\" xlink:href=\"#icon-star\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "<svg class=\"icon icon-star\">\n",
       "<use href=\"#icon-star\" xlink:href=\"#icon-star\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "<svg class=\"icon icon-star\">\n",
       "<use href=\"#icon-star\" xlink:href=\"#icon-star\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "<svg class=\"icon icon-star-half\">\n",
       "<use href=\"#icon-star-half\" xlink:href=\"#icon-star-half\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"></use>\n",
       "</svg>\n",
       "</div>\n",
       "<div class=\"mm-recipes-card-meta__rating-count-number mntl-recipe-card-meta__rating-count-number\">\n",
       "644\n",
       "<span class=\"mm-recipes-card-meta__rating-count-text mntl-recipe-card-meta__rating-count-text\">\n",
       "Ratings\n",
       "</span>\n",
       "</div>\n",
       "</div> </div>\n",
       "</a>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe = soup.find_all('a', class_ = 'comp mntl-card-list-items mntl-document-card mntl-card card card--no-image')\n",
    "recipe[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'mntl-card-list-items_1-0',\n",
       " 'class': ['comp',\n",
       "  'mntl-card-list-items',\n",
       "  'mntl-document-card',\n",
       "  'mntl-card',\n",
       "  'card',\n",
       "  'card--no-image'],\n",
       " 'data-doc-id': '6663943',\n",
       " 'data-tax-levels': '',\n",
       " 'href': 'https://www.allrecipes.com/recipe/219171/classic-meatloaf/',\n",
       " 'data-ordinal': '1'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe[0].attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.allrecipes.com/recipe/219171/classic-meatloaf/'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe[0].attrs['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding `href` to our dataframe of recipes\n",
    "\n",
    "Let's modify our `extract_recipes()` function such that rather than returning just the names of the dishes, it returns a list of dictionaries, where each dictionary has the `name` and `url` fields:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `from_dict`\n",
    "\n",
    "First, a useful tool to turn a dictionary into a data frame where the keys are features (columns) and the values are lists that correspond to the values of the features (rows) is the `pd.DataFrame.from_dict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>who</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>what</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>where</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>why</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2   col3\n",
       "0     1     6    who\n",
       "1     2     7   what\n",
       "2     3     8   when\n",
       "3     4     9  where\n",
       "4     5    10    why"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_dict = {'col1': [1,2,3,4,5],\n",
    "                'col2': [6,7,8,9,10],\n",
    "                'col3': ['who', 'what', 'when', 'where', 'why']}\n",
    "pd.DataFrame.from_dict(example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_recipes(text):\n",
    "    \"\"\" builds list of recipe names from allrecipies html\n",
    "    \n",
    "    Args:\n",
    "        html_str (str): html response from allrecipes.com, see crawl_recipes()\n",
    "        \n",
    "    Returns:\n",
    "        df_recipe (pd.DataFrame): dataframe of recipes\n",
    "    \"\"\"\n",
    "\n",
    "    soup = BeautifulSoup(text)\n",
    "    \n",
    "    recipe_list = []\n",
    "    for recipe in soup.find_all(class_ = 'card__title-text'):\n",
    "        recipe = recipe.text\n",
    "        recipe_list.append(recipe)\n",
    "\n",
    "    href_list = []\n",
    "    for recipe in soup.find_all('a', class_ = 'comp mntl-card-list-items mntl-document-card mntl-card card card--no-image'):\n",
    "        recipe_link = recipe.attrs['href']\n",
    "        href_list.append(recipe_link)\n",
    "\n",
    "    recipe_dict = {'name': recipe_list, \n",
    "                  'href': href_list}\n",
    "    df_recipe = pd.DataFrame.from_dict(recipe_dict)\n",
    "\n",
    "    return df_recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>href</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classic Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/219171/class...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Melt-In-Your-Mouth Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/223381/melt-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Best Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/74360/the-be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Easy Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/16354/easy-m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Creamy Mushroom Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/219963/cream...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meatloaf that Doesn't Crumble</td>\n",
       "      <td>https://www.allrecipes.com/recipe/79749/meatlo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Meatloaf Cupcakes</td>\n",
       "      <td>https://www.allrecipes.com/recipe/236847/meatl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Italian Style Turkey Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/234508/itali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Brown Sugar Meatloaf with Ketchup Glaze</td>\n",
       "      <td>https://www.allrecipes.com/recipe/238904/brown...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chris's Incredible Italian Turkey Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/31843/chriss...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Turkey and Quinoa Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/213211/turke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dill Pickle Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/169724/dill-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Kim's Ultimate Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/25144/kims-u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ellen's Buffalo Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/167087/ellen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sweet and Sour Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/18035/sweet-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Mushroom Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/14629/mushro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Chef John's Meatball-Inspired Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/238038/chef-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Best Turkey Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/231380/best-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Cottage Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/20621/cottag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tennessee Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/232247/tenne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Momma's Healthy Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/240747/momma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Best Ever Meatloaf with Brown Gravy</td>\n",
       "      <td>https://www.allrecipes.com/recipe/14644/best-e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Smoky Chipotle Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/214399/smoke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Cheeseburger Meatloaf</td>\n",
       "      <td>https://www.allrecipes.com/recipe/16189/cheese...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  \\\n",
       "0                             Classic Meatloaf   \n",
       "1                  Melt-In-Your-Mouth Meatloaf   \n",
       "2                                Best Meatloaf   \n",
       "3                                Easy Meatloaf   \n",
       "4                     Creamy Mushroom Meatloaf   \n",
       "5                Meatloaf that Doesn't Crumble   \n",
       "6                            Meatloaf Cupcakes   \n",
       "7                Italian Style Turkey Meatloaf   \n",
       "8      Brown Sugar Meatloaf with Ketchup Glaze   \n",
       "9   Chris's Incredible Italian Turkey Meatloaf   \n",
       "10                  Turkey and Quinoa Meatloaf   \n",
       "11                        Dill Pickle Meatloaf   \n",
       "12                     Kim's Ultimate Meatloaf   \n",
       "13                    Ellen's Buffalo Meatloaf   \n",
       "14                     Sweet and Sour Meatloaf   \n",
       "15                           Mushroom Meatloaf   \n",
       "16      Chef John's Meatball-Inspired Meatloaf   \n",
       "17                        Best Turkey Meatloaf   \n",
       "18                            Cottage Meatloaf   \n",
       "19                          Tennessee Meatloaf   \n",
       "20                    Momma's Healthy Meatloaf   \n",
       "21         Best Ever Meatloaf with Brown Gravy   \n",
       "22                     Smoky Chipotle Meatloaf   \n",
       "23                       Cheeseburger Meatloaf   \n",
       "\n",
       "                                                 href  \n",
       "0   https://www.allrecipes.com/recipe/219171/class...  \n",
       "1   https://www.allrecipes.com/recipe/223381/melt-...  \n",
       "2   https://www.allrecipes.com/recipe/74360/the-be...  \n",
       "3   https://www.allrecipes.com/recipe/16354/easy-m...  \n",
       "4   https://www.allrecipes.com/recipe/219963/cream...  \n",
       "5   https://www.allrecipes.com/recipe/79749/meatlo...  \n",
       "6   https://www.allrecipes.com/recipe/236847/meatl...  \n",
       "7   https://www.allrecipes.com/recipe/234508/itali...  \n",
       "8   https://www.allrecipes.com/recipe/238904/brown...  \n",
       "9   https://www.allrecipes.com/recipe/31843/chriss...  \n",
       "10  https://www.allrecipes.com/recipe/213211/turke...  \n",
       "11  https://www.allrecipes.com/recipe/169724/dill-...  \n",
       "12  https://www.allrecipes.com/recipe/25144/kims-u...  \n",
       "13  https://www.allrecipes.com/recipe/167087/ellen...  \n",
       "14  https://www.allrecipes.com/recipe/18035/sweet-...  \n",
       "15  https://www.allrecipes.com/recipe/14629/mushro...  \n",
       "16  https://www.allrecipes.com/recipe/238038/chef-...  \n",
       "17  https://www.allrecipes.com/recipe/231380/best-...  \n",
       "18  https://www.allrecipes.com/recipe/20621/cottag...  \n",
       "19  https://www.allrecipes.com/recipe/232247/tenne...  \n",
       "20  https://www.allrecipes.com/recipe/240747/momma...  \n",
       "21  https://www.allrecipes.com/recipe/14644/best-e...  \n",
       "22  https://www.allrecipes.com/recipe/214399/smoke...  \n",
       "23  https://www.allrecipes.com/recipe/16189/cheese...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_recipes(meatloaf_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Manipulations\n",
    "- `.split()` & `.join()`\n",
    "- `.strip()`\n",
    "- `.replace()`\n",
    "- `.upper()` & `.lower()`\n",
    "\n",
    "Visting [a specific recipe's page](https://www.allrecipes.com/recipe/219171/classic-meatloaf/) yields data stored in a string.  The methods above allow us to extract this information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello!  \\n hello!'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#.strip removes all leading and trailing whitespaces(newline)\n",
    "'\\n\\n\\n hello!  \\n hello! \\n \\n    \\n \\n'.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cheese+fondue'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'cheese fondue'.replace(' ', '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello George'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Hello Fred'.replace('Fred', 'George')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lets forget about, okay?'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'lets forget about it, okay?'.replace(' it', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DONT SHOUT'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'dont shout'.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'be quiet'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'BE Quiet'.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fat: 54 g', ' calories: 430 cal', ' sugar: 10g']"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split a string on every given string\n",
    "'fat: 54 g, calories: 430 cal, sugar: 10g'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abcd'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#join: glue something together\n",
    "''.join(['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a<glue>b<glue>c<glue>d'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'<glue>'.join(['a', 'b', 'c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = 'last0, first0, last1, first1, last2, first2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last0, first0'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = namelist.split(\",\")\n",
    "','.join(name[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'last1, first1'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "','.join(name[2:4]).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visit specific recipe's page\n",
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'\n",
    "html = requests.get(url).text\n",
    "soup = BeautifulSoup(html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "Write two functions: `extract_prep_info()` and `extract_nutrition()`, which both accept a url of a particular recipe (see examples above) and return dictionaries of the prep in of nutritional information, respectively. For example:\n",
    "\n",
    "```python\n",
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'\n",
    "extract_prep_info(url)\n",
    "extract_nutrition(url)\n",
    "\n",
    "```\n",
    "\n",
    "yields:\n",
    "\n",
    "```python\n",
    "prep_info_dict = {'Prep Time': '10 mins',\n",
    "                  'Cook Time': '15 mins',\n",
    "                  'Total Time': '25 mins',\n",
    "                  'Servings': '10',\n",
    "                  'Yield': '10 servings'}\n",
    "\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```python\n",
    "nutr_info_dict = {'Total Fat': '14g',\n",
    "                  'Saturated Fat': '9g',\n",
    "                  'Cholesterol': '46mg',\n",
    "                  'Sodium': '179mg',\n",
    "                  'Total Carbohydrate': '3g',\n",
    "                  'Total Sugars': '1g',\n",
    "                  'Protein': '13g',\n",
    "                  'Vitamin C': '0mg',\n",
    "                  'Calcium': '461mg',\n",
    "                  'Iron': '0mg',\n",
    "                  'Potassium': '67mg'}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_prep_info(url):\n",
    "    \"\"\" returns a dictionary of recipe preparation info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        prep_info_dict (dict): keys are features ('prep'), \n",
    "            vals are str that describe feature ('20 mins')\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are str of quantity ('24 g')\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipe/283561/classic-cheese-fondue/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grabbing numeric values (float/int) from messy strings\n",
    "\n",
    "- We have strings which describe recipe nutrition info (`'100 mg'`)\n",
    "- We want numeric data types (`float, int`) so that we can plot and operate on these values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rest of Class (Go slowly; if we don't finish we can next week)\n",
    "Complete the `extract_nutrition()` below such that:\n",
    "\n",
    "```python\n",
    "# get / extract a data frame of recipes (only name and href)\n",
    "str_query = 'boston cream pie'\n",
    "html_str = crawl_recipes(str_query)\n",
    "df_recipe = extract_recipes(html_str)\n",
    "\n",
    "for row_idx in range(df_recipe.shape[0]):\n",
    "    # get / extract nutrition info for a particular recipe\n",
    "    recipe_url = df_recipe.loc[row_idx, 'href']\n",
    "    nutr_dict = extract_nutrition(recipe_url)\n",
    "    \n",
    "    # add each new nutrition feature to the dataframe\n",
    "    # only if there ARE nutrition features\n",
    "    if len(nutr_dict) != 0:\n",
    "        for nutr_feat, nutr_val in nutr_dict.items():\n",
    "            df_recipe.loc[row_idx, nutr_feat] = nutr_val\n",
    "    else:\n",
    "        df_recipe = df_recipe.drop(row_idx, axis=0)\n",
    "\n",
    "```\n",
    "\n",
    "generates the `df_recipe`:\n",
    "\n",
    "|    | name                           | href                                              | Total Fat | Saturated Fat | Cholesterol | Sodium | Total Carbohydrate | Dietary Fiber | Total Sugars | Protein | Vitamin C | Calcium | Iron | Potassium |\n",
    "|----|--------------------------------|---------------------------------------------------|-----------|---------------|-------------|--------|--------------------|---------------|--------------|---------|-----------|---------|------|-----------|\n",
    "| 0  | Chef John's Boston Cream Pie   | https://www.allrecipes.com/recipe/220942/chef-... | 41        | 17            | 199         | 514    | 72                 | 2             | 46           | 10      | 0         | 168     | 2    | 230       |\n",
    "| 1  | Boston Cream Pie               | https://www.allrecipes.com/recipe/8138/boston-... | 13        | 6             | 61          | 230    | 47                 | 1             | 34           | 5       | 0         | 101     | 2    | 134       |\n",
    "| 2  | Boston Cream Pie I             | https://www.allrecipes.com/recipe/8137/boston-... | 15        | 9             | 94          | 223    | 43                 | 1             | 26           | 5       | 0         | 97      | 2    | 95        |\n",
    "| 3  | Semi-Homemade Boston Cream Pie | https://www.allrecipes.com/recipe/278930/semi-... | 41        | 16            | 219         | 568    | 79                 | 3             | 53           | 11      | 0         | 186     | 3    | 194       |\n",
    "| 9  | Hot Milk Sponge Cake II        | https://www.allrecipes.com/recipe/8159/hot-mil... | 3         | 2             | 52          | 231    | 34                 | 0             | 20           | 4       | NaN       | 61      | 2    | 60        |\n",
    "| 17 | Boston Cream Dessert Cups      | https://www.allrecipes.com/recipe/213446/bosto... | 15        | 7             | 44          | 237    | 32                 | 0             | 22           | 3       | 0         | 41      | 1    | 101       |\n",
    "| 19 | Boston Creme Mini-Cupcakes     | https://www.allrecipes.com/recipe/220809/bosto... | 12        | 4             | 32          | 253    | 34                 | 0             | 24           | 3       | 0         | 62      | 1    | 100       |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are floats of quantity ('24 g' = 24)\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.allrecipes.com/recipe/220942/chef-johns-boston-cream-pie/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nutrition(url):\n",
    "    \"\"\" returns a dictionary of nutrition info \n",
    "    \n",
    "    Args:\n",
    "        url (str): location of all recipes \"recipe\"\n",
    "        \n",
    "    Returns:\n",
    "        nutr_dict (dict): keys are molecule types ('fat'), \n",
    "            vals are floats of quantity ('24 g' = 24)\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together\n",
    "- get list of dictionaries corresponding to recipes (done!)\n",
    "- get dictionary of nutrition info per recipe (done!)\n",
    "- aggregating info into dataframe (see below)\n",
    "- scatter plot (up next)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_recipe(str_query, recipe_limit=None):\n",
    "    \"\"\" searches for recipes and returns list, with nutrition info\n",
    "    \n",
    "    Args:\n",
    "        str_query (str): search string\n",
    "        recipe_limit (int): if passed, limits recipe (helpful\n",
    "            to speed up nutrition scraping for teaching!)\n",
    "        \n",
    "    Returns:\n",
    "        df_recipe (pd.DataFrame): dataframe, each row is recipe.\n",
    "            includes columns href, name, and nutrition facts\n",
    "    \"\"\"    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
